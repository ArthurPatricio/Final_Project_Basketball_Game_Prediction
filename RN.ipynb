{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguagem, Bibliotecas e Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read NBA data from excel file\n",
    "\n",
    "nba_data = pd.read_excel('nba_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOME_TEAM_ID</th>\n",
       "      <th>HOME_TEAM_ABBREVIATION</th>\n",
       "      <th>HOME_GAME_ID</th>\n",
       "      <th>HOME_MATCHUP</th>\n",
       "      <th>HOME_SEASON</th>\n",
       "      <th>HOME_GAME_N</th>\n",
       "      <th>HOME_WL</th>\n",
       "      <th>AWAY_TEAM_ID</th>\n",
       "      <th>AWAY_TEAM_ABBREVIATION</th>\n",
       "      <th>AWAY_GAME_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>BLK_RANK_y</th>\n",
       "      <th>BLKA_RANK_y</th>\n",
       "      <th>PF_RANK_y</th>\n",
       "      <th>PFD_RANK_y</th>\n",
       "      <th>PTS_RANK_y</th>\n",
       "      <th>PLUS_MINUS_RANK_y</th>\n",
       "      <th>GAME_DATE_y</th>\n",
       "      <th>SEASON_y</th>\n",
       "      <th>GAME_N_y</th>\n",
       "      <th>COMPARE_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>WAS</td>\n",
       "      <td>22200019</td>\n",
       "      <td>WAS vs. CHI</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>2</td>\n",
       "      <td>W</td>\n",
       "      <td>1610612741</td>\n",
       "      <td>CHI</td>\n",
       "      <td>22200019</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-10-19-2022_23</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>2</td>\n",
       "      <td>2-1610612741-2022-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612739</td>\n",
       "      <td>CLE</td>\n",
       "      <td>22200039</td>\n",
       "      <td>CLE vs. WAS</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>3</td>\n",
       "      <td>W</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>WAS</td>\n",
       "      <td>22200039</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-10-21-2022_23</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>3</td>\n",
       "      <td>3-1610612764-2022-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>WAS</td>\n",
       "      <td>22200052</td>\n",
       "      <td>WAS vs. DET</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>4</td>\n",
       "      <td>W</td>\n",
       "      <td>1610612765</td>\n",
       "      <td>DET</td>\n",
       "      <td>22200052</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>2022-10-22-2022_23</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>4</td>\n",
       "      <td>4-1610612765-2022-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>WAS</td>\n",
       "      <td>22200074</td>\n",
       "      <td>WAS vs. IND</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>1610612754</td>\n",
       "      <td>IND</td>\n",
       "      <td>22200074</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>2022-10-26-2022_23</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>6</td>\n",
       "      <td>6-1610612754-2022-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612738</td>\n",
       "      <td>BOS</td>\n",
       "      <td>22200089</td>\n",
       "      <td>BOS vs. WAS</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>6</td>\n",
       "      <td>W</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>WAS</td>\n",
       "      <td>22200089</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>2022-10-28-2022_23</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>6</td>\n",
       "      <td>6-1610612764-2022-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HOME_TEAM_ID HOME_TEAM_ABBREVIATION  HOME_GAME_ID HOME_MATCHUP HOME_SEASON  \\\n",
       "0    1610612764                    WAS      22200019  WAS vs. CHI     2022-23   \n",
       "1    1610612739                    CLE      22200039  CLE vs. WAS     2022-23   \n",
       "2    1610612764                    WAS      22200052  WAS vs. DET     2022-23   \n",
       "3    1610612764                    WAS      22200074  WAS vs. IND     2022-23   \n",
       "4    1610612738                    BOS      22200089  BOS vs. WAS     2022-23   \n",
       "\n",
       "   HOME_GAME_N HOME_WL  AWAY_TEAM_ID AWAY_TEAM_ABBREVIATION  AWAY_GAME_ID  \\\n",
       "0            2       W    1610612741                    CHI      22200019   \n",
       "1            3       W    1610612764                    WAS      22200039   \n",
       "2            4       W    1610612765                    DET      22200052   \n",
       "3            5       L    1610612754                    IND      22200074   \n",
       "4            6       W    1610612764                    WAS      22200089   \n",
       "\n",
       "   ... BLK_RANK_y BLKA_RANK_y  PF_RANK_y PFD_RANK_y PTS_RANK_y  \\\n",
       "0  ...          6           2         25          8          8   \n",
       "1  ...          2           7          7         27         18   \n",
       "2  ...         28          30         10          7         17   \n",
       "3  ...          3          21         23         17         11   \n",
       "4  ...          5           7         19         23         20   \n",
       "\n",
       "  PLUS_MINUS_RANK_y         GAME_DATE_y SEASON_y  GAME_N_y  \\\n",
       "0                 7  2022-10-19-2022_23  2022-23         2   \n",
       "1                 9  2022-10-21-2022_23  2022-23         3   \n",
       "2                27  2022-10-22-2022_23  2022-23         4   \n",
       "3                25  2022-10-26-2022_23  2022-23         6   \n",
       "4                11  2022-10-28-2022_23  2022-23         6   \n",
       "\n",
       "              COMPARE_y  \n",
       "0  2-1610612741-2022-23  \n",
       "1  3-1610612764-2022-23  \n",
       "2  4-1610612765-2022-23  \n",
       "3  6-1610612754-2022-23  \n",
       "4  6-1610612764-2022-23  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop \"Unnamed: 0\" column\n",
    "\n",
    "nba_data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "nba_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6963, 132)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get nba_data dataframa shape\n",
    "\n",
    "nba_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HOME_TEAM_ID', 'HOME_TEAM_ABBREVIATION', 'HOME_GAME_ID',\n",
       "       'HOME_MATCHUP', 'HOME_SEASON', 'HOME_GAME_N', 'HOME_WL', 'AWAY_TEAM_ID',\n",
       "       'AWAY_TEAM_ABBREVIATION', 'AWAY_GAME_ID',\n",
       "       ...\n",
       "       'BLK_RANK_y', 'BLKA_RANK_y', 'PF_RANK_y', 'PFD_RANK_y', 'PTS_RANK_y',\n",
       "       'PLUS_MINUS_RANK_y', 'GAME_DATE_y', 'SEASON_y', 'GAME_N_y',\n",
       "       'COMPARE_y'],\n",
       "      dtype='object', length=132)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get nba_data dataframe columns\n",
    "\n",
    "nba_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOME_TEAM_ID</th>\n",
       "      <th>HOME_GAME_ID</th>\n",
       "      <th>HOME_GAME_N</th>\n",
       "      <th>AWAY_TEAM_ID</th>\n",
       "      <th>AWAY_GAME_ID</th>\n",
       "      <th>AWAY_GAME_N</th>\n",
       "      <th>TEAM_ID_x</th>\n",
       "      <th>GP_x</th>\n",
       "      <th>W_x</th>\n",
       "      <th>L_x</th>\n",
       "      <th>...</th>\n",
       "      <th>AST_RANK_y</th>\n",
       "      <th>TOV_RANK_y</th>\n",
       "      <th>STL_RANK_y</th>\n",
       "      <th>BLK_RANK_y</th>\n",
       "      <th>BLKA_RANK_y</th>\n",
       "      <th>PF_RANK_y</th>\n",
       "      <th>PFD_RANK_y</th>\n",
       "      <th>PTS_RANK_y</th>\n",
       "      <th>PLUS_MINUS_RANK_y</th>\n",
       "      <th>GAME_N_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.963000e+03</td>\n",
       "      <td>6.963000e+03</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6.963000e+03</td>\n",
       "      <td>6.963000e+03</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6.963000e+03</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "      <td>6963.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.195075e+07</td>\n",
       "      <td>40.421657</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.195075e+07</td>\n",
       "      <td>40.431567</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>39.421657</td>\n",
       "      <td>19.688640</td>\n",
       "      <td>19.733017</td>\n",
       "      <td>...</td>\n",
       "      <td>15.345541</td>\n",
       "      <td>15.321844</td>\n",
       "      <td>15.419647</td>\n",
       "      <td>15.286514</td>\n",
       "      <td>15.244004</td>\n",
       "      <td>15.371248</td>\n",
       "      <td>15.439466</td>\n",
       "      <td>15.327876</td>\n",
       "      <td>15.286227</td>\n",
       "      <td>40.431567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.653343e+00</td>\n",
       "      <td>1.743568e+05</td>\n",
       "      <td>22.634354</td>\n",
       "      <td>8.640874e+00</td>\n",
       "      <td>1.743568e+05</td>\n",
       "      <td>22.614953</td>\n",
       "      <td>8.653343e+00</td>\n",
       "      <td>22.634354</td>\n",
       "      <td>13.039842</td>\n",
       "      <td>13.080083</td>\n",
       "      <td>...</td>\n",
       "      <td>8.664255</td>\n",
       "      <td>8.648501</td>\n",
       "      <td>8.662756</td>\n",
       "      <td>8.643116</td>\n",
       "      <td>8.639085</td>\n",
       "      <td>8.656732</td>\n",
       "      <td>8.616650</td>\n",
       "      <td>8.637555</td>\n",
       "      <td>8.633215</td>\n",
       "      <td>22.614953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.170002e+07</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.170002e+07</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.180054e+07</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.180054e+07</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.200003e+07</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.200003e+07</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.210070e+07</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.210070e+07</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.220123e+07</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>2.220123e+07</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HOME_TEAM_ID  HOME_GAME_ID  HOME_GAME_N  AWAY_TEAM_ID  AWAY_GAME_ID  \\\n",
       "count  6.963000e+03  6.963000e+03  6963.000000  6.963000e+03  6.963000e+03   \n",
       "mean   1.610613e+09  2.195075e+07    40.421657  1.610613e+09  2.195075e+07   \n",
       "std    8.653343e+00  1.743568e+05    22.634354  8.640874e+00  1.743568e+05   \n",
       "min    1.610613e+09  2.170002e+07     2.000000  1.610613e+09  2.170002e+07   \n",
       "25%    1.610613e+09  2.180054e+07    21.000000  1.610613e+09  2.180054e+07   \n",
       "50%    1.610613e+09  2.200003e+07    40.000000  1.610613e+09  2.200003e+07   \n",
       "75%    1.610613e+09  2.210070e+07    60.000000  1.610613e+09  2.210070e+07   \n",
       "max    1.610613e+09  2.220123e+07    82.000000  1.610613e+09  2.220123e+07   \n",
       "\n",
       "       AWAY_GAME_N     TEAM_ID_x         GP_x          W_x          L_x  ...  \\\n",
       "count  6963.000000  6.963000e+03  6963.000000  6963.000000  6963.000000  ...   \n",
       "mean     40.431567  1.610613e+09    39.421657    19.688640    19.733017  ...   \n",
       "std      22.614953  8.653343e+00    22.634354    13.039842    13.080083  ...   \n",
       "min       2.000000  1.610613e+09     1.000000     0.000000     0.000000  ...   \n",
       "25%      21.000000  1.610613e+09    20.000000     9.000000     9.000000  ...   \n",
       "50%      40.000000  1.610613e+09    39.000000    18.000000    18.000000  ...   \n",
       "75%      60.000000  1.610613e+09    59.000000    29.000000    29.000000  ...   \n",
       "max      82.000000  1.610613e+09    81.000000    64.000000    64.000000  ...   \n",
       "\n",
       "        AST_RANK_y   TOV_RANK_y   STL_RANK_y   BLK_RANK_y  BLKA_RANK_y  \\\n",
       "count  6963.000000  6963.000000  6963.000000  6963.000000  6963.000000   \n",
       "mean     15.345541    15.321844    15.419647    15.286514    15.244004   \n",
       "std       8.664255     8.648501     8.662756     8.643116     8.639085   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%       8.000000     8.000000     8.000000     8.000000     8.000000   \n",
       "50%      15.000000    15.000000    15.000000    15.000000    15.000000   \n",
       "75%      23.000000    23.000000    23.000000    23.000000    23.000000   \n",
       "max      30.000000    30.000000    30.000000    30.000000    30.000000   \n",
       "\n",
       "         PF_RANK_y   PFD_RANK_y   PTS_RANK_y  PLUS_MINUS_RANK_y     GAME_N_y  \n",
       "count  6963.000000  6963.000000  6963.000000        6963.000000  6963.000000  \n",
       "mean     15.371248    15.439466    15.327876          15.286227    40.431567  \n",
       "std       8.656732     8.616650     8.637555           8.633215    22.614953  \n",
       "min       1.000000     1.000000     1.000000           1.000000     2.000000  \n",
       "25%       8.000000     8.000000     8.000000           8.000000    21.000000  \n",
       "50%      15.000000    16.000000    15.000000          15.000000    40.000000  \n",
       "75%      23.000000    23.000000    23.000000          23.000000    60.000000  \n",
       "max      30.000000    30.000000    30.000000          30.000000    82.000000  \n",
       "\n",
       "[8 rows x 114 columns]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get nba_data dataframe describe\n",
    "\n",
    "nba_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HOME_WL\n",
       "W    3936\n",
       "L    3027\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get classes\n",
    "\n",
    "nba_data['HOME_WL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6963 entries, 0 to 6962\n",
      "Columns: 132 entries, HOME_TEAM_ID to COMPARE_y\n",
      "dtypes: float64(46), int64(68), object(18)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get nba_data dataframe info\n",
    "\n",
    "nba_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chegagem de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msno.matrix(nba_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatório Pandas Profile\n",
    "\n",
    "    Foi gerado o 'Pandas Profile Report' que oferece uma análise extensa do conjunto de dados que está sendo abordado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset:  95%|█████████▍| 106/112 [00:02<00:00, 37.38it/s, Calculate auto correlation]         \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Generate and export as a .html file the Pandas Profile Report of the nba_shots dataframe\u001b[39;00m\n\u001b[0;32m      3\u001b[0m profile_data \u001b[39m=\u001b[39m ProfileReport(nba_data, title \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnba_data\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m profile_data\u001b[39m.\u001b[39;49mto_file(\u001b[39m\"\u001b[39;49m\u001b[39mnba_data_pandas_profile_report.html\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\typeguard\\__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[1;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\profile_report.py:309\u001b[0m, in \u001b[0;36mProfileReport.to_file\u001b[1;34m(self, output_file, silent)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mhtml\u001b[39m.\u001b[39massets_prefix \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(output_file\u001b[39m.\u001b[39mstem) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_assets\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m     create_html_assets(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig, output_file)\n\u001b[1;32m--> 309\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_html()\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m output_file\u001b[39m.\u001b[39msuffix \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.html\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    312\u001b[0m     suffix \u001b[39m=\u001b[39m output_file\u001b[39m.\u001b[39msuffix\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\typeguard\\__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[1;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\profile_report.py:420\u001b[0m, in \u001b[0;36mProfileReport.to_html\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_html\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    413\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate and return complete template as lengthy string\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[39m        for using with frameworks.\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m \n\u001b[0;32m    419\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhtml\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\typeguard\\__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[1;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\profile_report.py:231\u001b[0m, in \u001b[0;36mProfileReport.html\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhtml\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_html \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 231\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_html \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render_html()\n\u001b[0;32m    232\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_html\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\typeguard\\__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[1;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\profile_report.py:339\u001b[0m, in \u001b[0;36mProfileReport._render_html\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_render_html\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    337\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreport\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpresentation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mflavours\u001b[39;00m \u001b[39mimport\u001b[39;00m HTMLReport\n\u001b[1;32m--> 339\u001b[0m     report \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreport\n\u001b[0;32m    341\u001b[0m     \u001b[39mwith\u001b[39;00m tqdm(\n\u001b[0;32m    342\u001b[0m         total\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRender HTML\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mprogress_bar\n\u001b[0;32m    343\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m    344\u001b[0m         html \u001b[39m=\u001b[39m HTMLReport(copy\u001b[39m.\u001b[39mdeepcopy(report))\u001b[39m.\u001b[39mrender(\n\u001b[0;32m    345\u001b[0m             nav\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mhtml\u001b[39m.\u001b[39mnavbar_show,\n\u001b[0;32m    346\u001b[0m             offline\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mhtml\u001b[39m.\u001b[39muse_local_assets,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    354\u001b[0m             version\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdescription_set[\u001b[39m\"\u001b[39m\u001b[39mpackage\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mpandas_profiling_version\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    355\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\typeguard\\__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[1;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\profile_report.py:225\u001b[0m, in \u001b[0;36mProfileReport.report\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreport\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Root:\n\u001b[0;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report \u001b[39m=\u001b[39m get_report_structure(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdescription_set)\n\u001b[0;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\typeguard\\__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[1;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\profile_report.py:207\u001b[0m, in \u001b[0;36mProfileReport.description_set\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdescription_set\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m    206\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_description_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_description_set \u001b[39m=\u001b[39m describe_df(\n\u001b[0;32m    208\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig,\n\u001b[0;32m    209\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf,\n\u001b[0;32m    210\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msummarizer,\n\u001b[0;32m    211\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtypeset,\n\u001b[0;32m    212\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sample,\n\u001b[0;32m    213\u001b[0m         )\n\u001b[0;32m    214\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_description_set\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\model\\describe.py:97\u001b[0m, in \u001b[0;36mdescribe\u001b[1;34m(config, df, summarizer, typeset, sample)\u001b[0m\n\u001b[0;32m     94\u001b[0m correlation_names \u001b[39m=\u001b[39m get_active_correlations(config)\n\u001b[0;32m     95\u001b[0m pbar\u001b[39m.\u001b[39mtotal \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(correlation_names)\n\u001b[1;32m---> 97\u001b[0m correlations \u001b[39m=\u001b[39m {\n\u001b[0;32m     98\u001b[0m     correlation_name: progress(\n\u001b[0;32m     99\u001b[0m         calculate_correlation, pbar, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCalculate \u001b[39m\u001b[39m{\u001b[39;00mcorrelation_name\u001b[39m}\u001b[39;00m\u001b[39m correlation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m     )(config, df, correlation_name, series_description)\n\u001b[0;32m    101\u001b[0m     \u001b[39mfor\u001b[39;00m correlation_name \u001b[39min\u001b[39;00m correlation_names\n\u001b[0;32m    102\u001b[0m }\n\u001b[0;32m    104\u001b[0m \u001b[39m# make sure correlations is not None\u001b[39;00m\n\u001b[0;32m    105\u001b[0m correlations \u001b[39m=\u001b[39m {\n\u001b[0;32m    106\u001b[0m     key: value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m correlations\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    107\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\model\\describe.py:98\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     94\u001b[0m correlation_names \u001b[39m=\u001b[39m get_active_correlations(config)\n\u001b[0;32m     95\u001b[0m pbar\u001b[39m.\u001b[39mtotal \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(correlation_names)\n\u001b[0;32m     97\u001b[0m correlations \u001b[39m=\u001b[39m {\n\u001b[1;32m---> 98\u001b[0m     correlation_name: progress(\n\u001b[0;32m     99\u001b[0m         calculate_correlation, pbar, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mCalculate \u001b[39;49m\u001b[39m{\u001b[39;49;00mcorrelation_name\u001b[39m}\u001b[39;49;00m\u001b[39m correlation\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    100\u001b[0m     )(config, df, correlation_name, series_description)\n\u001b[0;32m    101\u001b[0m     \u001b[39mfor\u001b[39;00m correlation_name \u001b[39min\u001b[39;00m correlation_names\n\u001b[0;32m    102\u001b[0m }\n\u001b[0;32m    104\u001b[0m \u001b[39m# make sure correlations is not None\u001b[39;00m\n\u001b[0;32m    105\u001b[0m correlations \u001b[39m=\u001b[39m {\n\u001b[0;32m    106\u001b[0m     key: value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m correlations\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    107\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\utils\\progress_bar.py:11\u001b[0m, in \u001b[0;36mprogress.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     10\u001b[0m     bar\u001b[39m.\u001b[39mset_postfix_str(message)\n\u001b[1;32m---> 11\u001b[0m     ret \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     12\u001b[0m     bar\u001b[39m.\u001b[39mupdate()\n\u001b[0;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\model\\correlations.py:107\u001b[0m, in \u001b[0;36mcalculate_correlation\u001b[1;34m(config, df, correlation_name, summary)\u001b[0m\n\u001b[0;32m    105\u001b[0m correlation \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     correlation \u001b[39m=\u001b[39m correlation_measures[correlation_name]\u001b[39m.\u001b[39;49mcompute(\n\u001b[0;32m    108\u001b[0m         config, df, summary\n\u001b[0;32m    109\u001b[0m     )\n\u001b[0;32m    110\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mAssertionError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m, DataError, \u001b[39mIndexError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    111\u001b[0m     warn_correlation(correlation_name, \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\multimethod\\__init__.py:315\u001b[0m, in \u001b[0;36mmultimethod.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m[\u001b[39mtuple\u001b[39m(func(arg) \u001b[39mfor\u001b[39;00m func, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype_checkers, args))]\n\u001b[0;32m    314\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    316\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m    317\u001b[0m     \u001b[39mraise\u001b[39;00m DispatchError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFunction \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__code__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mex\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\model\\pandas\\correlations_pandas.py:203\u001b[0m, in \u001b[0;36mpandas_auto_compute\u001b[1;34m(config, df, summary)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(col_name: \u001b[39mstr\u001b[39m, method: Callable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mSeries:\n\u001b[0;32m    197\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    198\u001b[0m             df_discretized\n\u001b[0;32m    199\u001b[0m             \u001b[39mif\u001b[39;00m col_name \u001b[39min\u001b[39;00m numerical_columns \u001b[39mand\u001b[39;00m method \u001b[39mis\u001b[39;00m _pairwise_cramers\n\u001b[0;32m    200\u001b[0m             \u001b[39melse\u001b[39;00m df\n\u001b[0;32m    201\u001b[0m         )\n\u001b[1;32m--> 203\u001b[0m     score \u001b[39m=\u001b[39m method(\n\u001b[0;32m    204\u001b[0m         f(col_1_name, method)[col_1_name], f(col_2_name, method)[col_2_name]\n\u001b[0;32m    205\u001b[0m     )\n\u001b[0;32m    206\u001b[0m     (\n\u001b[0;32m    207\u001b[0m         correlation_matrix\u001b[39m.\u001b[39mloc[col_1_name, col_2_name],\n\u001b[0;32m    208\u001b[0m         correlation_matrix\u001b[39m.\u001b[39mloc[col_2_name, col_1_name],\n\u001b[0;32m    209\u001b[0m     ) \u001b[39m=\u001b[39m (score, score)\n\u001b[0;32m    211\u001b[0m \u001b[39mreturn\u001b[39;00m correlation_matrix\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas_profiling\\model\\pandas\\correlations_pandas.py:76\u001b[0m, in \u001b[0;36m_pairwise_spearman\u001b[1;34m(col_1, col_2)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pairwise_spearman\u001b[39m(col_1: pd\u001b[39m.\u001b[39mSeries, col_2: pd\u001b[39m.\u001b[39mSeries) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m col_1\u001b[39m.\u001b[39;49mcorr(col_2, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mspearman\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:2727\u001b[0m, in \u001b[0;36mSeries.corr\u001b[1;34m(self, other, method, min_periods)\u001b[0m\n\u001b[0;32m   2724\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m   2726\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mspearman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkendall\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m \u001b[39mcallable\u001b[39m(method):\n\u001b[1;32m-> 2727\u001b[0m     \u001b[39mreturn\u001b[39;00m nanops\u001b[39m.\u001b[39;49mnancorr(\n\u001b[0;32m   2728\u001b[0m         this\u001b[39m.\u001b[39;49mvalues, other\u001b[39m.\u001b[39;49mvalues, method\u001b[39m=\u001b[39;49mmethod, min_periods\u001b[39m=\u001b[39;49mmin_periods\n\u001b[0;32m   2729\u001b[0m     )\n\u001b[0;32m   2731\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2732\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmethod must be either \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2733\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mspearman\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mkendall\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or a callable, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2734\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmethod\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was supplied\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2735\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:1614\u001b[0m, in \u001b[0;36mnancorr\u001b[1;34m(a, b, method, min_periods)\u001b[0m\n\u001b[0;32m   1611\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m   1613\u001b[0m f \u001b[39m=\u001b[39m get_corr_func(method)\n\u001b[1;32m-> 1614\u001b[0m \u001b[39mreturn\u001b[39;00m f(a, b)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:1631\u001b[0m, in \u001b[0;36mget_corr_func.<locals>.func\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m   1630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(a, b):\n\u001b[1;32m-> 1631\u001b[0m     \u001b[39mreturn\u001b[39;00m spearmanr(a, b)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\_stats_py.py:5474\u001b[0m, in \u001b[0;36mspearmanr\u001b[1;34m(a, b, axis, nan_policy, alternative)\u001b[0m\n\u001b[0;32m   5469\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5470\u001b[0m             \u001b[39m# Keep track of variables with NaNs, set the outputs to NaN\u001b[39;00m\n\u001b[0;32m   5471\u001b[0m             \u001b[39m# only for those variables\u001b[39;00m\n\u001b[0;32m   5472\u001b[0m             variable_has_nan \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misnan(a)\u001b[39m.\u001b[39many(axis\u001b[39m=\u001b[39maxisout)\n\u001b[1;32m-> 5474\u001b[0m a_ranked \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mapply_along_axis(rankdata, axisout, a)\n\u001b[0;32m   5475\u001b[0m rs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcorrcoef(a_ranked, rowvar\u001b[39m=\u001b[39maxisout)\n\u001b[0;32m   5476\u001b[0m dof \u001b[39m=\u001b[39m n_obs \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m  \u001b[39m# degrees of freedom\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\shape_base.py:379\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    376\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    377\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    378\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 379\u001b[0m res \u001b[39m=\u001b[39m asanyarray(func1d(inarr_view[ind0], \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[0;32m    381\u001b[0m \u001b[39m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[0;32m    385\u001b[0m buff \u001b[39m=\u001b[39m zeros(inarr_view\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m res\u001b[39m.\u001b[39mshape, res\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\_stats_py.py:10236\u001b[0m, in \u001b[0;36mrankdata\u001b[1;34m(a, method, axis, nan_policy)\u001b[0m\n\u001b[0;32m  10233\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mfull_like(arr, np\u001b[39m.\u001b[39mnan)\n\u001b[0;32m  10235\u001b[0m algo \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmergesort\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mordinal\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mquicksort\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m> 10236\u001b[0m sorter \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margsort(arr, kind\u001b[39m=\u001b[39;49malgo)\n\u001b[0;32m  10238\u001b[0m inv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(sorter\u001b[39m.\u001b[39msize, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[0;32m  10239\u001b[0m inv[sorter] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(sorter\u001b[39m.\u001b[39msize, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margsort\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1120\u001b[0m, in \u001b[0;36margsort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[0;32m   1013\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39margsort\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, kind\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1014\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[39m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \n\u001b[0;32m   1119\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1120\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39margsort\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, kind\u001b[39m=\u001b[39;49mkind, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[1;32mc:\\Users\\arthu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate and export as a .html file the Pandas Profile Report of the nba_shots dataframe\n",
    "\n",
    "profile_data = ProfileReport(nba_data, title ='nba_data')\n",
    "profile_data.to_file(\"nba_data_pandas_profile_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Profile Report in this notebook\n",
    "\n",
    "profile_data.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsão de resultados utilizando Redes Neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Columns\n",
    "\n",
    "nba_data.drop(nba_data.columns[[0,1,2,3,4,5,7,8,9,10,11,12,13,14,\n",
    "                                  15,16,17,70,71,72,73,74,75,128,129,130,131]], axis=1, inplace=True)\n",
    "\n",
    "nba_data.to_excel('test_table.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOME_WL</th>\n",
       "      <th>GP_x</th>\n",
       "      <th>W_x</th>\n",
       "      <th>L_x</th>\n",
       "      <th>W_PCT_x</th>\n",
       "      <th>MIN_x</th>\n",
       "      <th>FGM_x</th>\n",
       "      <th>FGA_x</th>\n",
       "      <th>FG_PCT_x</th>\n",
       "      <th>FG3M_x</th>\n",
       "      <th>...</th>\n",
       "      <th>REB_RANK_y</th>\n",
       "      <th>AST_RANK_y</th>\n",
       "      <th>TOV_RANK_y</th>\n",
       "      <th>STL_RANK_y</th>\n",
       "      <th>BLK_RANK_y</th>\n",
       "      <th>BLKA_RANK_y</th>\n",
       "      <th>PF_RANK_y</th>\n",
       "      <th>PFD_RANK_y</th>\n",
       "      <th>PTS_RANK_y</th>\n",
       "      <th>PLUS_MINUS_RANK_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.457</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>48.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.531</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.667</td>\n",
       "      <td>49.7</td>\n",
       "      <td>42.0</td>\n",
       "      <td>86.3</td>\n",
       "      <td>0.486</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>49.3</td>\n",
       "      <td>42.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.494</td>\n",
       "      <td>10.8</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>49.0</td>\n",
       "      <td>41.6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>15.2</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HOME_WL  GP_x  W_x  L_x  W_PCT_x  MIN_x  FGM_x  FGA_x  FG_PCT_x  FG3M_x  \\\n",
       "0        0     1    1    0    1.000   48.0   42.0   92.0     0.457    11.0   \n",
       "1        0     2    1    1    0.500   48.0   43.0   81.0     0.531    13.0   \n",
       "2        0     3    2    1    0.667   49.7   42.0   86.3     0.486    11.0   \n",
       "3        1     4    3    1    0.750   49.3   42.5   86.0     0.494    10.8   \n",
       "4        0     5    3    2    0.600   49.0   41.6   86.0     0.484    15.2   \n",
       "\n",
       "   ...  REB_RANK_y  AST_RANK_y  TOV_RANK_y  STL_RANK_y  BLK_RANK_y  \\\n",
       "0  ...          12          15          14           2           6   \n",
       "1  ...          10          17          24          21           2   \n",
       "2  ...           8           9           9          14          28   \n",
       "3  ...           9           7          16          26           3   \n",
       "4  ...          24          14          23          21           5   \n",
       "\n",
       "   BLKA_RANK_y  PF_RANK_y  PFD_RANK_y  PTS_RANK_y  PLUS_MINUS_RANK_y  \n",
       "0            2         25           8           8                  7  \n",
       "1            7          7          27          18                  9  \n",
       "2           30         10           7          17                 27  \n",
       "3           21         23          17          11                 25  \n",
       "4            7         19          23          20                 11  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn categorical column HOME_WL into numerial\n",
    "\n",
    "nba_data['HOME_WL'] = nba_data['HOME_WL'].apply(lambda x: 0 if x == 'W' else 1)\n",
    "nba_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate database in train and test\n",
    "\n",
    "X = nba_data.loc[:, nba_data.columns != 'HOME_WL']\n",
    "y = nba_data['HOME_WL']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size= 0.3, \n",
    "                                                    random_state = 100, \n",
    "                                                    stratify = y,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train e X_test possuíam 0 atributo(s) com variância igual a zero \n",
      "\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False] \n",
      "\n",
      "X_train: (4874, 104)\n",
      "X_test: (2089, 104)\n",
      "y_train: (4874,)\n",
      "y_test: (2089,)\n"
     ]
    }
   ],
   "source": [
    "# Check columns with variance equal to zero and drop them\n",
    "\n",
    "zero_var_filter = VarianceThreshold()\n",
    "X_train = zero_var_filter.fit_transform(X_train)\n",
    "X_test = zero_var_filter.transform(X_test)\n",
    "print('X_train e X_test possuíam', (zero_var_filter.variances_ == 0).sum(), 'atributo(s) com variância igual a zero \\n')\n",
    "\n",
    "print(zero_var_filter.variances_ == 0, '\\n')\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19390183, -0.51290067,  0.17945249, ..., -0.17228294,\n",
       "        -0.60944706,  0.07584392],\n",
       "       [-1.61094241, -1.43070805, -1.36273462, ...,  1.22296558,\n",
       "         0.88705677,  1.1184542 ],\n",
       "       [-1.21239975, -1.43070805, -0.66875042, ...,  0.06025848,\n",
       "        -1.18502546, -1.19845753],\n",
       "       ...,\n",
       "       [ 0.95744365,  0.94029435,  0.71921797, ..., -1.21871934,\n",
       "        -1.06990978,  1.00260862],\n",
       "       [ 0.69174854,  1.47568199, -0.28320365, ...,  0.87415345,\n",
       "         1.46263517,  0.53922627],\n",
       "       [-1.38952982, -1.12477225, -1.28562526, ..., -1.21871934,\n",
       "         0.19636269, -1.31430312]])"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "preprocessParams = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_normalized = preprocessParams.transform(X_train)\n",
    "X_test_normalized = preprocessParams.transform(X_test)\n",
    "\n",
    "X_train_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Train Neural Network\n",
    "\n",
    "NumberOfClasses = len(y_train.unique())\n",
    "NumberOfClasses\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_154 (Dense)           (None, 25)                2625      \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 12)                312       \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 5)                 65        \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3014 (11.77 KB)\n",
      "Trainable params: 3014 (11.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "\n",
    "RN = Sequential()\n",
    "RN.add(Dense(25,input_shape = X_train_normalized.shape[1:],activation = 'sigmoid'))\n",
    "RN.add(Dense(12,activation = 'sigmoid'))\n",
    "RN.add(Dense(5,activation = 'sigmoid'))\n",
    "RN.add(Dense(NumberOfClasses,activation = 'sigmoid'))\n",
    "RN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "107/107 [==============================] - 1s 3ms/step - loss: 0.7374 - accuracy: 0.4298 - val_loss: 0.7186 - val_accuracy: 0.4463\n",
      "Epoch 2/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7140 - accuracy: 0.4298 - val_loss: 0.7038 - val_accuracy: 0.4463\n",
      "Epoch 3/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.7009 - accuracy: 0.4298 - val_loss: 0.6958 - val_accuracy: 0.4463\n",
      "Epoch 4/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.4981 - val_loss: 0.6915 - val_accuracy: 0.5537\n",
      "Epoch 5/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5702 - val_loss: 0.6893 - val_accuracy: 0.5537\n",
      "Epoch 6/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5702 - val_loss: 0.6881 - val_accuracy: 0.5537\n",
      "Epoch 7/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 8/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5702 - val_loss: 0.6874 - val_accuracy: 0.5537\n",
      "Epoch 9/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5702 - val_loss: 0.6873 - val_accuracy: 0.5537\n",
      "Epoch 10/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5702 - val_loss: 0.6873 - val_accuracy: 0.5537\n",
      "Epoch 11/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.5702 - val_loss: 0.6874 - val_accuracy: 0.5537\n",
      "Epoch 12/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5702 - val_loss: 0.6874 - val_accuracy: 0.5537\n",
      "Epoch 13/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5702 - val_loss: 0.6875 - val_accuracy: 0.5537\n",
      "Epoch 14/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.5702 - val_loss: 0.6875 - val_accuracy: 0.5537\n",
      "Epoch 15/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 16/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 17/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 18/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 19/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 20/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 21/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 22/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 23/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 24/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 25/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 26/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 27/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 28/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 29/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 30/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5702 - val_loss: 0.6875 - val_accuracy: 0.5537\n",
      "Epoch 31/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 32/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5702 - val_loss: 0.6876 - val_accuracy: 0.5537\n",
      "Epoch 33/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5702 - val_loss: 0.6875 - val_accuracy: 0.5537\n",
      "Epoch 34/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5702 - val_loss: 0.6875 - val_accuracy: 0.5537\n",
      "Epoch 35/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5702 - val_loss: 0.6875 - val_accuracy: 0.5537\n",
      "Epoch 36/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5702 - val_loss: 0.6875 - val_accuracy: 0.5537\n",
      "Epoch 37/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5702 - val_loss: 0.6875 - val_accuracy: 0.5537\n",
      "Epoch 38/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5702 - val_loss: 0.6874 - val_accuracy: 0.5537\n",
      "Epoch 39/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5702 - val_loss: 0.6874 - val_accuracy: 0.5537\n",
      "Epoch 40/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5702 - val_loss: 0.6874 - val_accuracy: 0.5537\n",
      "Epoch 41/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5702 - val_loss: 0.6874 - val_accuracy: 0.5537\n",
      "Epoch 42/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5702 - val_loss: 0.6874 - val_accuracy: 0.5537\n",
      "Epoch 43/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5702 - val_loss: 0.6874 - val_accuracy: 0.5537\n",
      "Epoch 44/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5702 - val_loss: 0.6874 - val_accuracy: 0.5537\n",
      "Epoch 45/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.5702 - val_loss: 0.6873 - val_accuracy: 0.5537\n",
      "Epoch 46/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5702 - val_loss: 0.6873 - val_accuracy: 0.5537\n",
      "Epoch 47/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5702 - val_loss: 0.6873 - val_accuracy: 0.5537\n",
      "Epoch 48/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5702 - val_loss: 0.6873 - val_accuracy: 0.5537\n",
      "Epoch 49/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5702 - val_loss: 0.6873 - val_accuracy: 0.5537\n",
      "Epoch 50/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5702 - val_loss: 0.6872 - val_accuracy: 0.5537\n",
      "Epoch 51/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.5702 - val_loss: 0.6872 - val_accuracy: 0.5537\n",
      "Epoch 52/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5702 - val_loss: 0.6872 - val_accuracy: 0.5537\n",
      "Epoch 53/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5702 - val_loss: 0.6872 - val_accuracy: 0.5537\n",
      "Epoch 54/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5702 - val_loss: 0.6872 - val_accuracy: 0.5537\n",
      "Epoch 55/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5702 - val_loss: 0.6872 - val_accuracy: 0.5537\n",
      "Epoch 56/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5702 - val_loss: 0.6872 - val_accuracy: 0.5537\n",
      "Epoch 57/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6826 - accuracy: 0.5702 - val_loss: 0.6871 - val_accuracy: 0.5537\n",
      "Epoch 58/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5702 - val_loss: 0.6871 - val_accuracy: 0.5537\n",
      "Epoch 59/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5702 - val_loss: 0.6871 - val_accuracy: 0.5537\n",
      "Epoch 60/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5702 - val_loss: 0.6871 - val_accuracy: 0.5537\n",
      "Epoch 61/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5702 - val_loss: 0.6871 - val_accuracy: 0.5537\n",
      "Epoch 62/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5702 - val_loss: 0.6870 - val_accuracy: 0.5537\n",
      "Epoch 63/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5702 - val_loss: 0.6870 - val_accuracy: 0.5537\n",
      "Epoch 64/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5702 - val_loss: 0.6870 - val_accuracy: 0.5537\n",
      "Epoch 65/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5702 - val_loss: 0.6870 - val_accuracy: 0.5537\n",
      "Epoch 66/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5702 - val_loss: 0.6870 - val_accuracy: 0.5537\n",
      "Epoch 67/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5702 - val_loss: 0.6870 - val_accuracy: 0.5537\n",
      "Epoch 68/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5702 - val_loss: 0.6869 - val_accuracy: 0.5537\n",
      "Epoch 69/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5702 - val_loss: 0.6869 - val_accuracy: 0.5537\n",
      "Epoch 70/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5702 - val_loss: 0.6869 - val_accuracy: 0.5537\n",
      "Epoch 71/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5702 - val_loss: 0.6868 - val_accuracy: 0.5537\n",
      "Epoch 72/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5702 - val_loss: 0.6868 - val_accuracy: 0.5537\n",
      "Epoch 73/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5702 - val_loss: 0.6868 - val_accuracy: 0.5537\n",
      "Epoch 74/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5702 - val_loss: 0.6868 - val_accuracy: 0.5537\n",
      "Epoch 75/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5702 - val_loss: 0.6868 - val_accuracy: 0.5537\n",
      "Epoch 76/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5702 - val_loss: 0.6868 - val_accuracy: 0.5537\n",
      "Epoch 77/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5702 - val_loss: 0.6867 - val_accuracy: 0.5537\n",
      "Epoch 78/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5702 - val_loss: 0.6867 - val_accuracy: 0.5537\n",
      "Epoch 79/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5702 - val_loss: 0.6867 - val_accuracy: 0.5537\n",
      "Epoch 80/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5702 - val_loss: 0.6867 - val_accuracy: 0.5537\n",
      "Epoch 81/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.5702 - val_loss: 0.6866 - val_accuracy: 0.5537\n",
      "Epoch 82/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5702 - val_loss: 0.6866 - val_accuracy: 0.5537\n",
      "Epoch 83/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6821 - accuracy: 0.5702 - val_loss: 0.6866 - val_accuracy: 0.5537\n",
      "Epoch 84/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5702 - val_loss: 0.6865 - val_accuracy: 0.5537\n",
      "Epoch 85/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5702 - val_loss: 0.6865 - val_accuracy: 0.5537\n",
      "Epoch 86/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5702 - val_loss: 0.6865 - val_accuracy: 0.5537\n",
      "Epoch 87/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5702 - val_loss: 0.6865 - val_accuracy: 0.5537\n",
      "Epoch 88/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5702 - val_loss: 0.6865 - val_accuracy: 0.5537\n",
      "Epoch 89/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5702 - val_loss: 0.6864 - val_accuracy: 0.5537\n",
      "Epoch 90/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5702 - val_loss: 0.6864 - val_accuracy: 0.5537\n",
      "Epoch 91/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6819 - accuracy: 0.5702 - val_loss: 0.6864 - val_accuracy: 0.5537\n",
      "Epoch 92/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5702 - val_loss: 0.6864 - val_accuracy: 0.5537\n",
      "Epoch 93/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5702 - val_loss: 0.6863 - val_accuracy: 0.5537\n",
      "Epoch 94/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5702 - val_loss: 0.6863 - val_accuracy: 0.5537\n",
      "Epoch 95/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5702 - val_loss: 0.6863 - val_accuracy: 0.5537\n",
      "Epoch 96/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5702 - val_loss: 0.6863 - val_accuracy: 0.5537\n",
      "Epoch 97/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5702 - val_loss: 0.6862 - val_accuracy: 0.5537\n",
      "Epoch 98/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5702 - val_loss: 0.6862 - val_accuracy: 0.5537\n",
      "Epoch 99/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.5702 - val_loss: 0.6862 - val_accuracy: 0.5537\n",
      "Epoch 100/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5702 - val_loss: 0.6862 - val_accuracy: 0.5537\n",
      "Epoch 101/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5702 - val_loss: 0.6861 - val_accuracy: 0.5537\n",
      "Epoch 102/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.5702 - val_loss: 0.6861 - val_accuracy: 0.5537\n",
      "Epoch 103/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5702 - val_loss: 0.6861 - val_accuracy: 0.5537\n",
      "Epoch 104/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5702 - val_loss: 0.6860 - val_accuracy: 0.5537\n",
      "Epoch 105/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5702 - val_loss: 0.6860 - val_accuracy: 0.5537\n",
      "Epoch 106/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5702 - val_loss: 0.6860 - val_accuracy: 0.5537\n",
      "Epoch 107/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5702 - val_loss: 0.6860 - val_accuracy: 0.5537\n",
      "Epoch 108/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5702 - val_loss: 0.6859 - val_accuracy: 0.5537\n",
      "Epoch 109/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.5702 - val_loss: 0.6859 - val_accuracy: 0.5537\n",
      "Epoch 110/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.5702 - val_loss: 0.6859 - val_accuracy: 0.5537\n",
      "Epoch 111/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5702 - val_loss: 0.6858 - val_accuracy: 0.5537\n",
      "Epoch 112/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.5702 - val_loss: 0.6858 - val_accuracy: 0.5537\n",
      "Epoch 113/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.5702 - val_loss: 0.6857 - val_accuracy: 0.5537\n",
      "Epoch 114/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.5702 - val_loss: 0.6857 - val_accuracy: 0.5537\n",
      "Epoch 115/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5702 - val_loss: 0.6857 - val_accuracy: 0.5537\n",
      "Epoch 116/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5702 - val_loss: 0.6857 - val_accuracy: 0.5537\n",
      "Epoch 117/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.5702 - val_loss: 0.6856 - val_accuracy: 0.5537\n",
      "Epoch 118/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5702 - val_loss: 0.6856 - val_accuracy: 0.5537\n",
      "Epoch 119/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5702 - val_loss: 0.6855 - val_accuracy: 0.5537\n",
      "Epoch 120/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.5702 - val_loss: 0.6855 - val_accuracy: 0.5537\n",
      "Epoch 121/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5702 - val_loss: 0.6854 - val_accuracy: 0.5537\n",
      "Epoch 122/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5702 - val_loss: 0.6854 - val_accuracy: 0.5537\n",
      "Epoch 123/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5702 - val_loss: 0.6854 - val_accuracy: 0.5537\n",
      "Epoch 124/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5702 - val_loss: 0.6853 - val_accuracy: 0.5537\n",
      "Epoch 125/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5702 - val_loss: 0.6853 - val_accuracy: 0.5537\n",
      "Epoch 126/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5702 - val_loss: 0.6853 - val_accuracy: 0.5537\n",
      "Epoch 127/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5702 - val_loss: 0.6853 - val_accuracy: 0.5537\n",
      "Epoch 128/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.5702 - val_loss: 0.6852 - val_accuracy: 0.5537\n",
      "Epoch 129/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.5702 - val_loss: 0.6851 - val_accuracy: 0.5537\n",
      "Epoch 130/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5702 - val_loss: 0.6851 - val_accuracy: 0.5537\n",
      "Epoch 131/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.5702 - val_loss: 0.6850 - val_accuracy: 0.5537\n",
      "Epoch 132/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5702 - val_loss: 0.6850 - val_accuracy: 0.5537\n",
      "Epoch 133/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5702 - val_loss: 0.6849 - val_accuracy: 0.5537\n",
      "Epoch 134/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5702 - val_loss: 0.6849 - val_accuracy: 0.5537\n",
      "Epoch 135/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5702 - val_loss: 0.6848 - val_accuracy: 0.5537\n",
      "Epoch 136/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5702 - val_loss: 0.6848 - val_accuracy: 0.5537\n",
      "Epoch 137/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.5702 - val_loss: 0.6847 - val_accuracy: 0.5537\n",
      "Epoch 138/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5702 - val_loss: 0.6847 - val_accuracy: 0.5537\n",
      "Epoch 139/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5702 - val_loss: 0.6846 - val_accuracy: 0.5537\n",
      "Epoch 140/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5702 - val_loss: 0.6846 - val_accuracy: 0.5537\n",
      "Epoch 141/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5702 - val_loss: 0.6845 - val_accuracy: 0.5537\n",
      "Epoch 142/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5702 - val_loss: 0.6845 - val_accuracy: 0.5537\n",
      "Epoch 143/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.5702 - val_loss: 0.6844 - val_accuracy: 0.5537\n",
      "Epoch 144/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.5702 - val_loss: 0.6843 - val_accuracy: 0.5537\n",
      "Epoch 145/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5702 - val_loss: 0.6843 - val_accuracy: 0.5537\n",
      "Epoch 146/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5702 - val_loss: 0.6842 - val_accuracy: 0.5537\n",
      "Epoch 147/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5702 - val_loss: 0.6841 - val_accuracy: 0.5537\n",
      "Epoch 148/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5702 - val_loss: 0.6841 - val_accuracy: 0.5537\n",
      "Epoch 149/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.5702 - val_loss: 0.6840 - val_accuracy: 0.5537\n",
      "Epoch 150/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.5702 - val_loss: 0.6839 - val_accuracy: 0.5537\n",
      "Epoch 151/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5702 - val_loss: 0.6839 - val_accuracy: 0.5537\n",
      "Epoch 152/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5702 - val_loss: 0.6838 - val_accuracy: 0.5537\n",
      "Epoch 153/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.5702 - val_loss: 0.6838 - val_accuracy: 0.5537\n",
      "Epoch 154/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5702 - val_loss: 0.6837 - val_accuracy: 0.5537\n",
      "Epoch 155/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.5702 - val_loss: 0.6836 - val_accuracy: 0.5537\n",
      "Epoch 156/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.5702 - val_loss: 0.6836 - val_accuracy: 0.5537\n",
      "Epoch 157/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.5702 - val_loss: 0.6834 - val_accuracy: 0.5537\n",
      "Epoch 158/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.5702 - val_loss: 0.6834 - val_accuracy: 0.5537\n",
      "Epoch 159/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5702 - val_loss: 0.6833 - val_accuracy: 0.5537\n",
      "Epoch 160/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.5702 - val_loss: 0.6832 - val_accuracy: 0.5537\n",
      "Epoch 161/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.5702 - val_loss: 0.6831 - val_accuracy: 0.5537\n",
      "Epoch 162/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6785 - accuracy: 0.5702 - val_loss: 0.6830 - val_accuracy: 0.5537\n",
      "Epoch 163/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.5702 - val_loss: 0.6829 - val_accuracy: 0.5537\n",
      "Epoch 164/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.5702 - val_loss: 0.6828 - val_accuracy: 0.5537\n",
      "Epoch 165/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6782 - accuracy: 0.5702 - val_loss: 0.6827 - val_accuracy: 0.5537\n",
      "Epoch 166/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.5702 - val_loss: 0.6826 - val_accuracy: 0.5537\n",
      "Epoch 167/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5702 - val_loss: 0.6825 - val_accuracy: 0.5537\n",
      "Epoch 168/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6779 - accuracy: 0.5702 - val_loss: 0.6824 - val_accuracy: 0.5537\n",
      "Epoch 169/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.5702 - val_loss: 0.6823 - val_accuracy: 0.5537\n",
      "Epoch 170/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6777 - accuracy: 0.5702 - val_loss: 0.6822 - val_accuracy: 0.5537\n",
      "Epoch 171/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.5702 - val_loss: 0.6821 - val_accuracy: 0.5537\n",
      "Epoch 172/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.5702 - val_loss: 0.6820 - val_accuracy: 0.5537\n",
      "Epoch 173/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.5702 - val_loss: 0.6819 - val_accuracy: 0.5537\n",
      "Epoch 174/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.5702 - val_loss: 0.6818 - val_accuracy: 0.5537\n",
      "Epoch 175/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6772 - accuracy: 0.5702 - val_loss: 0.6817 - val_accuracy: 0.5537\n",
      "Epoch 176/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6771 - accuracy: 0.5702 - val_loss: 0.6816 - val_accuracy: 0.5537\n",
      "Epoch 177/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6769 - accuracy: 0.5702 - val_loss: 0.6814 - val_accuracy: 0.5537\n",
      "Epoch 178/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6768 - accuracy: 0.5702 - val_loss: 0.6813 - val_accuracy: 0.5537\n",
      "Epoch 179/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.5702 - val_loss: 0.6812 - val_accuracy: 0.5537\n",
      "Epoch 180/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.5702 - val_loss: 0.6810 - val_accuracy: 0.5537\n",
      "Epoch 181/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.5702 - val_loss: 0.6809 - val_accuracy: 0.5537\n",
      "Epoch 182/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.5702 - val_loss: 0.6808 - val_accuracy: 0.5537\n",
      "Epoch 183/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5702 - val_loss: 0.6806 - val_accuracy: 0.5537\n",
      "Epoch 184/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5702 - val_loss: 0.6805 - val_accuracy: 0.5537\n",
      "Epoch 185/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6759 - accuracy: 0.5702 - val_loss: 0.6803 - val_accuracy: 0.5537\n",
      "Epoch 186/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.5702 - val_loss: 0.6802 - val_accuracy: 0.5537\n",
      "Epoch 187/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.5702 - val_loss: 0.6801 - val_accuracy: 0.5537\n",
      "Epoch 188/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.5702 - val_loss: 0.6799 - val_accuracy: 0.5537\n",
      "Epoch 189/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.5702 - val_loss: 0.6797 - val_accuracy: 0.5537\n",
      "Epoch 190/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5702 - val_loss: 0.6796 - val_accuracy: 0.5537\n",
      "Epoch 191/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5702 - val_loss: 0.6794 - val_accuracy: 0.5537\n",
      "Epoch 192/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6748 - accuracy: 0.5702 - val_loss: 0.6792 - val_accuracy: 0.5537\n",
      "Epoch 193/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6746 - accuracy: 0.5702 - val_loss: 0.6791 - val_accuracy: 0.5537\n",
      "Epoch 194/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5702 - val_loss: 0.6789 - val_accuracy: 0.5537\n",
      "Epoch 195/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.5702 - val_loss: 0.6788 - val_accuracy: 0.5537\n",
      "Epoch 196/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.5702 - val_loss: 0.6786 - val_accuracy: 0.5537\n",
      "Epoch 197/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6738 - accuracy: 0.5702 - val_loss: 0.6784 - val_accuracy: 0.5537\n",
      "Epoch 198/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 0.5702 - val_loss: 0.6781 - val_accuracy: 0.5537\n",
      "Epoch 199/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.5702 - val_loss: 0.6780 - val_accuracy: 0.5537\n",
      "Epoch 200/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.5702 - val_loss: 0.6778 - val_accuracy: 0.5537\n",
      "Epoch 201/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.5702 - val_loss: 0.6775 - val_accuracy: 0.5537\n",
      "Epoch 202/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.5702 - val_loss: 0.6773 - val_accuracy: 0.5537\n",
      "Epoch 203/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6726 - accuracy: 0.5702 - val_loss: 0.6771 - val_accuracy: 0.5537\n",
      "Epoch 204/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6724 - accuracy: 0.5702 - val_loss: 0.6769 - val_accuracy: 0.5537\n",
      "Epoch 205/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.5702 - val_loss: 0.6767 - val_accuracy: 0.5537\n",
      "Epoch 206/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.5702 - val_loss: 0.6765 - val_accuracy: 0.5537\n",
      "Epoch 207/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6717 - accuracy: 0.5702 - val_loss: 0.6762 - val_accuracy: 0.5537\n",
      "Epoch 208/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.5702 - val_loss: 0.6759 - val_accuracy: 0.5537\n",
      "Epoch 209/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6712 - accuracy: 0.5702 - val_loss: 0.6757 - val_accuracy: 0.5537\n",
      "Epoch 210/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5702 - val_loss: 0.6754 - val_accuracy: 0.5537\n",
      "Epoch 211/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.5702 - val_loss: 0.6751 - val_accuracy: 0.5537\n",
      "Epoch 212/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.5702 - val_loss: 0.6749 - val_accuracy: 0.5537\n",
      "Epoch 213/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6701 - accuracy: 0.5702 - val_loss: 0.6746 - val_accuracy: 0.5537\n",
      "Epoch 214/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.5702 - val_loss: 0.6744 - val_accuracy: 0.5537\n",
      "Epoch 215/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.5702 - val_loss: 0.6741 - val_accuracy: 0.5537\n",
      "Epoch 216/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.5702 - val_loss: 0.6738 - val_accuracy: 0.5537\n",
      "Epoch 217/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6689 - accuracy: 0.5702 - val_loss: 0.6735 - val_accuracy: 0.5537\n",
      "Epoch 218/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.5702 - val_loss: 0.6732 - val_accuracy: 0.5537\n",
      "Epoch 219/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6683 - accuracy: 0.5702 - val_loss: 0.6729 - val_accuracy: 0.5537\n",
      "Epoch 220/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.5702 - val_loss: 0.6725 - val_accuracy: 0.5537\n",
      "Epoch 221/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6677 - accuracy: 0.5702 - val_loss: 0.6722 - val_accuracy: 0.5537\n",
      "Epoch 222/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.5702 - val_loss: 0.6719 - val_accuracy: 0.5543\n",
      "Epoch 223/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.5708 - val_loss: 0.6716 - val_accuracy: 0.5550\n",
      "Epoch 224/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.5705 - val_loss: 0.6712 - val_accuracy: 0.5550\n",
      "Epoch 225/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6663 - accuracy: 0.5711 - val_loss: 0.6709 - val_accuracy: 0.5557\n",
      "Epoch 226/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.5702 - val_loss: 0.6705 - val_accuracy: 0.5571\n",
      "Epoch 227/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.5737 - val_loss: 0.6702 - val_accuracy: 0.5564\n",
      "Epoch 228/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.5749 - val_loss: 0.6698 - val_accuracy: 0.5584\n",
      "Epoch 229/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.5764 - val_loss: 0.6694 - val_accuracy: 0.5605\n",
      "Epoch 230/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.5781 - val_loss: 0.6690 - val_accuracy: 0.5619\n",
      "Epoch 231/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6641 - accuracy: 0.5796 - val_loss: 0.6686 - val_accuracy: 0.5680\n",
      "Epoch 232/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.5805 - val_loss: 0.6682 - val_accuracy: 0.5680\n",
      "Epoch 233/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.5822 - val_loss: 0.6678 - val_accuracy: 0.5735\n",
      "Epoch 234/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.5866 - val_loss: 0.6674 - val_accuracy: 0.5728\n",
      "Epoch 235/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.5878 - val_loss: 0.6671 - val_accuracy: 0.5728\n",
      "Epoch 236/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.5837 - val_loss: 0.6666 - val_accuracy: 0.5776\n",
      "Epoch 237/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.5904 - val_loss: 0.6662 - val_accuracy: 0.5789\n",
      "Epoch 238/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6611 - accuracy: 0.5919 - val_loss: 0.6658 - val_accuracy: 0.5810\n",
      "Epoch 239/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.5922 - val_loss: 0.6654 - val_accuracy: 0.5824\n",
      "Epoch 240/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.5931 - val_loss: 0.6649 - val_accuracy: 0.5844\n",
      "Epoch 241/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.6013 - val_loss: 0.6645 - val_accuracy: 0.5851\n",
      "Epoch 242/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6025 - val_loss: 0.6641 - val_accuracy: 0.5865\n",
      "Epoch 243/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6589 - accuracy: 0.6051 - val_loss: 0.6637 - val_accuracy: 0.5858\n",
      "Epoch 244/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6042 - val_loss: 0.6632 - val_accuracy: 0.5913\n",
      "Epoch 245/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6063 - val_loss: 0.6627 - val_accuracy: 0.5954\n",
      "Epoch 246/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6121 - val_loss: 0.6623 - val_accuracy: 0.5947\n",
      "Epoch 247/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6133 - val_loss: 0.6618 - val_accuracy: 0.5960\n",
      "Epoch 248/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6159 - val_loss: 0.6613 - val_accuracy: 0.6008\n",
      "Epoch 249/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6180 - val_loss: 0.6608 - val_accuracy: 0.5981\n",
      "Epoch 250/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6174 - val_loss: 0.6604 - val_accuracy: 0.5988\n",
      "Epoch 251/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6201 - val_loss: 0.6599 - val_accuracy: 0.5988\n",
      "Epoch 252/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6183 - val_loss: 0.6595 - val_accuracy: 0.6008\n",
      "Epoch 253/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6212 - val_loss: 0.6590 - val_accuracy: 0.6015\n",
      "Epoch 254/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6236 - val_loss: 0.6585 - val_accuracy: 0.6029\n",
      "Epoch 255/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6256 - val_loss: 0.6581 - val_accuracy: 0.6056\n",
      "Epoch 256/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6277 - val_loss: 0.6576 - val_accuracy: 0.6083\n",
      "Epoch 257/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6280 - val_loss: 0.6571 - val_accuracy: 0.6097\n",
      "Epoch 258/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6309 - val_loss: 0.6567 - val_accuracy: 0.6104\n",
      "Epoch 259/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6321 - val_loss: 0.6562 - val_accuracy: 0.6131\n",
      "Epoch 260/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6330 - val_loss: 0.6558 - val_accuracy: 0.6104\n",
      "Epoch 261/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6315 - val_loss: 0.6553 - val_accuracy: 0.6145\n",
      "Epoch 262/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6321 - val_loss: 0.6549 - val_accuracy: 0.6152\n",
      "Epoch 263/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6327 - val_loss: 0.6544 - val_accuracy: 0.6118\n",
      "Epoch 264/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6341 - val_loss: 0.6540 - val_accuracy: 0.6118\n",
      "Epoch 265/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6373 - val_loss: 0.6536 - val_accuracy: 0.6165\n",
      "Epoch 266/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6368 - val_loss: 0.6532 - val_accuracy: 0.6165\n",
      "Epoch 267/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6371 - val_loss: 0.6527 - val_accuracy: 0.6152\n",
      "Epoch 268/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6373 - val_loss: 0.6523 - val_accuracy: 0.6152\n",
      "Epoch 269/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6464 - accuracy: 0.6368 - val_loss: 0.6519 - val_accuracy: 0.6159\n",
      "Epoch 270/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.6391 - val_loss: 0.6515 - val_accuracy: 0.6152\n",
      "Epoch 271/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6397 - val_loss: 0.6511 - val_accuracy: 0.6152\n",
      "Epoch 272/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6451 - accuracy: 0.6406 - val_loss: 0.6508 - val_accuracy: 0.6138\n",
      "Epoch 273/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6446 - accuracy: 0.6406 - val_loss: 0.6504 - val_accuracy: 0.6159\n",
      "Epoch 274/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6420 - val_loss: 0.6500 - val_accuracy: 0.6138\n",
      "Epoch 275/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.6438 - val_loss: 0.6496 - val_accuracy: 0.6179\n",
      "Epoch 276/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6434 - accuracy: 0.6453 - val_loss: 0.6492 - val_accuracy: 0.6165\n",
      "Epoch 277/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.6453 - val_loss: 0.6490 - val_accuracy: 0.6172\n",
      "Epoch 278/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6459 - val_loss: 0.6486 - val_accuracy: 0.6165\n",
      "Epoch 279/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6422 - accuracy: 0.6450 - val_loss: 0.6483 - val_accuracy: 0.6179\n",
      "Epoch 280/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6438 - val_loss: 0.6479 - val_accuracy: 0.6186\n",
      "Epoch 281/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.6432 - val_loss: 0.6476 - val_accuracy: 0.6165\n",
      "Epoch 282/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6456 - val_loss: 0.6474 - val_accuracy: 0.6165\n",
      "Epoch 283/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.6435 - val_loss: 0.6470 - val_accuracy: 0.6179\n",
      "Epoch 284/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6403 - accuracy: 0.6450 - val_loss: 0.6467 - val_accuracy: 0.6186\n",
      "Epoch 285/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.6444 - val_loss: 0.6465 - val_accuracy: 0.6193\n",
      "Epoch 286/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6396 - accuracy: 0.6450 - val_loss: 0.6462 - val_accuracy: 0.6213\n",
      "Epoch 287/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.6441 - val_loss: 0.6460 - val_accuracy: 0.6220\n",
      "Epoch 288/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.6438 - val_loss: 0.6457 - val_accuracy: 0.6220\n",
      "Epoch 289/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.6444 - val_loss: 0.6455 - val_accuracy: 0.6227\n",
      "Epoch 290/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.6453 - val_loss: 0.6452 - val_accuracy: 0.6241\n",
      "Epoch 291/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6380 - accuracy: 0.6453 - val_loss: 0.6450 - val_accuracy: 0.6247\n",
      "Epoch 292/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6377 - accuracy: 0.6453 - val_loss: 0.6448 - val_accuracy: 0.6247\n",
      "Epoch 293/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.6447 - val_loss: 0.6446 - val_accuracy: 0.6268\n",
      "Epoch 294/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6372 - accuracy: 0.6435 - val_loss: 0.6444 - val_accuracy: 0.6261\n",
      "Epoch 295/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6369 - accuracy: 0.6444 - val_loss: 0.6442 - val_accuracy: 0.6254\n",
      "Epoch 296/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.6438 - val_loss: 0.6441 - val_accuracy: 0.6261\n",
      "Epoch 297/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 0.6456 - val_loss: 0.6439 - val_accuracy: 0.6261\n",
      "Epoch 298/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6461 - val_loss: 0.6437 - val_accuracy: 0.6254\n",
      "Epoch 299/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6453 - val_loss: 0.6435 - val_accuracy: 0.6261\n",
      "Epoch 300/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6447 - val_loss: 0.6434 - val_accuracy: 0.6275\n",
      "Epoch 301/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.6459 - val_loss: 0.6432 - val_accuracy: 0.6295\n",
      "Epoch 302/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6459 - val_loss: 0.6431 - val_accuracy: 0.6295\n",
      "Epoch 303/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.6467 - val_loss: 0.6430 - val_accuracy: 0.6288\n",
      "Epoch 304/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6347 - accuracy: 0.6456 - val_loss: 0.6429 - val_accuracy: 0.6282\n",
      "Epoch 305/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.6456 - val_loss: 0.6427 - val_accuracy: 0.6282\n",
      "Epoch 306/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6459 - val_loss: 0.6426 - val_accuracy: 0.6302\n",
      "Epoch 307/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6341 - accuracy: 0.6470 - val_loss: 0.6424 - val_accuracy: 0.6329\n",
      "Epoch 308/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.6464 - val_loss: 0.6423 - val_accuracy: 0.6323\n",
      "Epoch 309/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6464 - val_loss: 0.6423 - val_accuracy: 0.6316\n",
      "Epoch 310/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.6470 - val_loss: 0.6422 - val_accuracy: 0.6309\n",
      "Epoch 311/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6333 - accuracy: 0.6464 - val_loss: 0.6421 - val_accuracy: 0.6309\n",
      "Epoch 312/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.6473 - val_loss: 0.6420 - val_accuracy: 0.6316\n",
      "Epoch 313/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6476 - val_loss: 0.6420 - val_accuracy: 0.6309\n",
      "Epoch 314/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.6464 - val_loss: 0.6419 - val_accuracy: 0.6323\n",
      "Epoch 315/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.6488 - val_loss: 0.6418 - val_accuracy: 0.6323\n",
      "Epoch 316/600\n",
      "107/107 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6488 - val_loss: 0.6418 - val_accuracy: 0.6316\n",
      "Epoch 317/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6323 - accuracy: 0.6467 - val_loss: 0.6416 - val_accuracy: 0.6302\n",
      "Epoch 318/600\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6322 - accuracy: 0.6500 - val_loss: 0.6416 - val_accuracy: 0.6302\n",
      "Epoch 319/600\n",
      " 57/107 [==============>...............] - ETA: 0s - loss: 0.6281 - accuracy: 0.6557\n",
      "Reached 65.0% accuracy so cancelling training!\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.6505 - val_loss: 0.6415 - val_accuracy: 0.6302\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "accuracy_threshold = 0.65\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epochs, logs={}) :\n",
    "        if(logs.get('accuracy') is not None and logs.get('accuracy') >= accuracy_threshold) :\n",
    "            print('\\nReached 65.0% accuracy so cancelling training!')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "RN.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy']) \n",
    "history = RN.fit(X_train_normalized, to_categorical(y_train), epochs = 600, \n",
    "                    batch_size=32, validation_split=0.3, callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss score: 0.6362946629524231\n",
      "Test accuracy: 0.643848717212677\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "score = RN.evaluate(X_test_normalized, to_categorical(y_test), verbose = 0)\n",
    "print('Test loss score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16a98b89030>"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training chart: Training and validation per loss and epochs\n",
    "\n",
    "#plt.plot(history.history['loss'], label='perda-treino')\n",
    "#plt.plot(history.history['val_loss'], label='validação')\n",
    "plt.plot(history.history['accuracy'], label='acurácia-treino')\n",
    "plt.plot(history.history['val_accuracy'], label='acurácia-validação')\n",
    "plt.title('Acurácia treino')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
